# ARSynthesis

The code shown in this project is the technical part of a Masters research project conducted by Pol Piella at the University of York. It attempts at changing how user interaction is performed for digital synthesizers and merge the world of AR and sound synthesis together. 

## Getting Started

To use the project, just download this xcode project, deploy the app to your device and start using. There is a getting started button to make the start very quick!

### Prerequisites

The minimum iOS must be at least iOS 11.3 and XCode 9.3.

```
For examples of the project, watch the following demo videos:
https://www.youtube.com/watch?v=F15ZQgvsqcI&t=11s
https://www.youtube.com/watch?v=P2xjMSCe_-I&t=1s
```


## Built With

* [AudioKit](http://audiokit.io) - The audio framework used.
* [ARKit](https://developer.apple.com/arkit/) - The augmented reality framework used.


We use [Fastlane](http://fastlane.co/) for versioning.

## Authors

* **Pol Piella** - *University of York* - [Pol Piella](https://github.com/polpa)


## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details


